{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from sedona.register import SedonaRegistrator\n",
    "from pyspark.sql import SparkSession\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "from sedona.sql.types import GeometryType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/usr/local/spark-3.0.1-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "org.apache.sedona#sedona-python-adapter-3.0_2.12 added as a dependency\n",
      "org.postgresql#postgresql added as a dependency\n",
      "org.datasyslab#geotools-wrapper added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-2645c16a-7612-41ec-8bdd-5397b60cf11c;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.sedona#sedona-python-adapter-3.0_2.12;1.0.0-incubating in central\n",
      "\tfound org.locationtech.jts#jts-core;1.18.0 in central\n",
      "\tfound org.wololo#jts2geojson;0.14.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.10.0 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.10.0 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.10.0.pr1 in central\n",
      "\tfound org.apache.sedona#sedona-core-3.0_2.12;1.0.0-incubating in central\n",
      "\tfound org.apache.sedona#sedona-sql-3.0_2.12;1.0.0-incubating in central\n",
      "\tfound org.postgresql#postgresql;42.2.23 in central\n",
      "\tfound org.checkerframework#checker-qual;3.5.0 in central\n",
      "\tfound org.datasyslab#geotools-wrapper;geotools-24.0 in central\n",
      ":: resolution report :: resolve 370ms :: artifacts dl 15ms\n",
      "\t:: modules in use:\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.10.0.pr1 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.10.0 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.10.0 from central in [default]\n",
      "\torg.apache.sedona#sedona-core-3.0_2.12;1.0.0-incubating from central in [default]\n",
      "\torg.apache.sedona#sedona-python-adapter-3.0_2.12;1.0.0-incubating from central in [default]\n",
      "\torg.apache.sedona#sedona-sql-3.0_2.12;1.0.0-incubating from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.5.0 from central in [default]\n",
      "\torg.datasyslab#geotools-wrapper;geotools-24.0 from central in [default]\n",
      "\torg.locationtech.jts#jts-core;1.18.0 from central in [default]\n",
      "\torg.postgresql#postgresql;42.2.23 from central in [default]\n",
      "\torg.wololo#jts2geojson;0.14.3 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.locationtech.jts#jts-core;1.16.1 by [org.locationtech.jts#jts-core;1.18.0] in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.10.0 by [com.fasterxml.jackson.core#jackson-annotations;2.10.0.pr1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   13  |   0   |   0   |   2   ||   11  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-2645c16a-7612-41ec-8bdd-5397b60cf11c\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 11 already retrieved (0kB/10ms)\n",
      "21/08/15 18:44:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.\\\n",
    "    builder.\\\n",
    "    appName(\"apache-sedona\").\\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName). \\\n",
    "    config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName). \\\n",
    "    config(\"spark.jars.packages\", \"org.apache.sedona:sedona-python-adapter-3.0_2.12:1.0.0-incubating,org.postgresql:postgresql:42.2.23,org.datasyslab:geotools-wrapper:geotools-24.0\") . \\\n",
    "    master(\"local[*]\").\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SedonaRegistrator.registerAll(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from sedona.sql.types import GeometryType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "point_data = [\n",
    "    [1, Point(21, 52)],\n",
    "    [2, Point(21, 52)],\n",
    "    [3, Point(21, 52)],\n",
    "    [4, Point(21, 52)],\n",
    "    [5, Point(21, 52)],\n",
    "    [6, Point(21, 52)]\n",
    "]\n",
    "\n",
    "gdf = gpd.GeoDataFrame(point_data, columns=[\"id\", \"geom\"])\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", IntegerType(), False),\n",
    "        StructField(\"geom\", GeometryType(), False),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "spark_gdf = spark.createDataFrame(gdf, schema)\n",
    "\n",
    "spark_gdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From spark to geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_data = [[1, \"POINT(21 52)\"], [2, \"POINT(21 52)\"]]\n",
    "\n",
    "spark_gdf = spark.createDataFrame(point_data).\\\n",
    "    selectExpr(\"_1 AS id\", \"ST_GeomFromText(_2) AS geom\")\n",
    "\n",
    "pd_dataframe = spark_gdf.toPandas()\n",
    "\n",
    "gdf = gpd.GeoDataFrame(pd_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geopandas.geodataframe.GeoDataFrame"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|         geom|\n",
      "+---+-------------+\n",
      "|  1|POINT (21 52)|\n",
      "|  2|POINT (21 52)|\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_gdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
